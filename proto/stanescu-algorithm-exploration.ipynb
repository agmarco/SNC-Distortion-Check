{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "\n",
    "from proto.visualization import slices_interactive, compare_volumes_interactive, compare_volumes, slider\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('../tmp/mri-001-axial.mat')['voxels']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inverted = 2*np.mean(data) - data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slices_interactive(data_inverted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import filters\n",
    "\n",
    "def unsharp_mask(image, sigma, weight):\n",
    "    '''\n",
    "    There are many ways to define an \"unsharp\" mask, \n",
    "    however this is a pretty standard one.\n",
    "    \n",
    "    NOTE: there is no \"threshold\" here.  It would be\n",
    "    easy to add, however.  See:\n",
    "    \n",
    "        http://www.damiensymonds.net/tut_usm.html\n",
    "        \n",
    "    for details on how it is typically implemented.\n",
    "    '''\n",
    "    blurred = filters.gaussian_filter(image, sigma)\n",
    "    return image - weight*blurred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_inverted_unsharp = unsharp_mask(data_inverted, 5, 1)\n",
    "compare_volumes_interactive(data_inverted, data_inverted_unsharp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adaptive_threshold(data):\n",
    "    thresholded = np.empty_like(data, dtype='b')\n",
    "    for iz in range(data.shape[2]):\n",
    "        thresholded[:, :, iz] = data[:, :, iz] > np.median(data[:, :, iz])\n",
    "    return thresholded\n",
    "\n",
    "thresholded = adaptive_threshold(data_inverted_unsharp)\n",
    "\n",
    "compare_volumes_interactive(data_inverted, thresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "kernel_length = 31\n",
    "kernel_unnormalized = signal.gaussian(kernel_length, std=5)\n",
    "kernel = kernel_unnormalized / np.sum(kernel_unnormalized)\n",
    "\n",
    "plt.plot(kernel, '-o')\n",
    "plt.title(\"Gaussian Kernel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresholded_as_float = thresholded.astype('f')\n",
    "kernel_x = np.reshape(kernel, (kernel_length, 1, 1))\n",
    "blurred_x = signal.convolve(thresholded_as_float, kernel_x, 'same')\n",
    "\n",
    "kernel_y = np.reshape(kernel, (1, kernel_length, 1))\n",
    "blurred_y = signal.convolve(thresholded_as_float, kernel_y, 'same')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_volumes_interactive(blurred_x, blurred_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred_xy = blurred_x + blurred_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assume that `blurred_x` and `blurred_y` will have the same \"maximum\" value, M.\n",
    "# M likely occurs\n",
    "# If this is the case, then the overlapping points will have a value of 2*M, and the intermediate\n",
    "# lines in the grid will have a value of about M, hence we want to threshold at 3/4*(2*M)\n",
    "blurred_xy_thresholded = blurred_xy > np.max(blurred_xy)*3/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_volumes_interactive(blurred_xy, blurred_xy_thresholded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.ndimage import distance_transform_cdt, label, watershed_ift\n",
    "\n",
    "# NOTE: this watershed algorithm is not finished\n",
    "# I stopped working on it, because after some consideration, it does not seem\n",
    "# like we even need to bother doing watersheding, as all of the points appear \n",
    "# properly separated already.\n",
    "\n",
    "def watershed_segmentation(binary_array):\n",
    "    distance = distance_transform_cdt(binary_array)\n",
    "    #local_maximums = peak_local_max(distance, indices=False, footprint=np.ones((3, 3, 3)), labels=binary_array)\n",
    "    markers = label(local_maximums)\n",
    "    # TODO: finish this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import ndimage\n",
    "\n",
    "labeled, num_features = ndimage.label(blurred_xy_thresholded)\n",
    "\n",
    "slices_interactive(labeled, cmap='jet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def histogram_of_feature_sizes(labeled_array):\n",
    "    labeled_array_flattened = labeled_array.flatten()\n",
    "    labeled_array_flattened_excluding_background = labeled_array_flattened[labeled_array_flattened > 0]\n",
    "    feature_sizes = np.bincount(labeled_array_flattened_excluding_background)\n",
    "    plt.plot(feature_sizes[4:1000])\n",
    "    plt.xlabel('Size (# of Voxels)')\n",
    "    plt.ylabel('Label Count')\n",
    "\n",
    "def reject_outliers(data, m = 2.0):\n",
    "    distance_from_median = np.abs(data - np.median(data))\n",
    "    median_distance_from_median = np.median(distance_from_median)\n",
    "    if median_distance_from_median == 0:\n",
    "        return data\n",
    "    else:\n",
    "        return data[distance_from_median <= m*median_distance_from_median]\n",
    "    \n",
    "\n",
    "histogram_of_feature_sizes(labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prune_features(labeled_array, min_size, max_size):\n",
    "    '''\n",
    "    Remove features that have too many or too few pixels.\n",
    "    '''\n",
    "    feature_sizes = np.bincount(labeled_array.flatten())\n",
    "    remaining_features_array = np.logical_and(feature_sizes >= min_size, feature_sizes <= max_size)\n",
    "    remaining_features = np.nonzero(remaining_features_array)\n",
    "\n",
    "    labeled_array_flat = labeled_array.flatten()\n",
    "    features_pruned = np.in1d(labeled_array_flat, remaining_features)\n",
    "    features_pruned.resize(*labeled_array.shape)\n",
    "    return features_pruned\n",
    "\n",
    "def min_max_thresholdb(min_val, max_val):\n",
    "    '''\n",
    "    Tool to help identify the min and max threshold values.\n",
    "    \n",
    "    Of course, this will have to be done automatically in the final algorithm!\n",
    "    '''\n",
    "    blurred_xy_thresholded_pruned = prune_features(labeled, min_val, max_val)\n",
    "    compare_volumes(blurred_xy_thresholded_pruned, blurred_xy_thresholded, 63)\n",
    "    compare_volumes(blurred_xy_thresholded_pruned, blurred_xy_thresholded, 78)\n",
    "    compare_volumes(blurred_xy_thresholded_pruned, blurred_xy_thresholded, 96)\n",
    "    \n",
    "keywords = {\n",
    "    'min_val': slider(100),\n",
    "    'max_val': slider(1000),\n",
    "}\n",
    "widgets.interact(min_max_thresholdb, **keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the max/min thresholds are manually determined using the previous\n",
    "# interactive block; eventually this step will need to be automated\n",
    "blurred_xy_thresholded_pruned = prune_features(labeled, 50, 500)\n",
    "labeled_pruned, number_of_labels = ndimage.label(blurred_xy_thresholded_pruned)\n",
    "# NOTE: it is not clear whether `data` should be the first argument \n",
    "# here;  need to think about this more\n",
    "grid_intersections = ndimage.center_of_mass(data, labeled_pruned, range(1, number_of_labels + 1))\n",
    "x, y, z = zip(*grid_intersections)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "fig = plt.figure(figsize=(10, 10))\n",
    "ax = fig.add_subplot(111, projection='3d')\n",
    "ax.scatter(x, y, z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {
   "attach-environment": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
